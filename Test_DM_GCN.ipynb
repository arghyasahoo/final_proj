{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc_yRD5Os-qO",
        "outputId": "e2432773-8466-4028-db04-1e3a878da8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DM-GCN'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 87 (delta 14), reused 38 (delta 14), pack-reused 48\u001b[K\n",
            "Unpacking objects: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pangsg/DM-GCN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.chdir(\"/content/DM-GCN\")"
      ],
      "metadata": {
        "id": "8M0NQXt5tfnF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset \"Tweets\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V48nmEk5tBrb",
        "outputId": "d72f8ec3-8c87-40e9-c1b4-93a1504c4a98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------  Configuration Arguments -----------\n",
            "batch_size: 32\n",
            "beta: 0.0001\n",
            "dataset: Tweets\n",
            "decay_epoch: 5\n",
            "dep_dim: 30\n",
            "direct: False\n",
            "emb_dim: 300\n",
            "gcn_dropout: 0.4\n",
            "head_num: 3\n",
            "hidden_dim: 300\n",
            "input_dropout: 0.7\n",
            "l2reg: 1e-05\n",
            "log: logs.txt\n",
            "log_step: 20\n",
            "loop: True\n",
            "lower: True\n",
            "lr: 0.001\n",
            "num_class: 3\n",
            "num_epoch: 100\n",
            "num_layers: 2\n",
            "optimizer: Adma\n",
            "pos_dim: 30\n",
            "post_dim: 30\n",
            "rnn_hidden: 300\n",
            "save_dir: ./saved_models\n",
            "second_layer: max\n",
            "seed: 241824186\n",
            "theta: 1.0\n",
            "top_k: 2\n",
            "------------------------------------------------\n",
            "Loading data from Tweets with batch size 32...\n",
            "190 batches created for ./dataset/Tweets/train.json\n",
            "22 batches created for ./dataset/Tweets/test.json\n",
            "Directory ./saved_models do not exist; creating...\n",
            "\n",
            "epoch:1\n",
            "train_loss: 1.0423, train_acc: 47.0312\n",
            "train_loss: 1.0320, train_acc: 49.0625\n",
            "train_loss: 1.0187, train_acc: 49.4792\n",
            "train_loss: 0.9963, train_acc: 51.5625\n",
            "train_loss: 0.9952, train_acc: 51.4688\n",
            "train_loss: 0.9837, train_acc: 52.3698\n",
            "train_loss: 0.9726, train_acc: 53.1920\n",
            "train_loss: 0.9630, train_acc: 54.2383\n",
            "train_loss: 0.9581, train_acc: 54.5660\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.9562, test_loss: 0.8279, train_acc: 54.6601, test_acc: 57.5000, f1_score: 0.4925\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:2\n",
            "train_loss: 0.9085, train_acc: 56.5625\n",
            "train_loss: 0.9047, train_acc: 57.4219\n",
            "train_loss: 0.8910, train_acc: 58.1771\n",
            "train_loss: 0.8723, train_acc: 59.5312\n",
            "train_loss: 0.8676, train_acc: 60.1250\n",
            "train_loss: 0.8612, train_acc: 60.6250\n",
            "train_loss: 0.8632, train_acc: 60.7143\n",
            "train_loss: 0.8558, train_acc: 61.0352\n",
            "train_loss: 0.8540, train_acc: 61.1458\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.8530, test_loss: 0.7461, train_acc: 61.1568, test_acc: 69.2614, f1_score: 0.6553\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:3\n",
            "train_loss: 0.8288, train_acc: 63.2812\n",
            "train_loss: 0.8341, train_acc: 63.1250\n",
            "train_loss: 0.8229, train_acc: 63.2292\n",
            "train_loss: 0.7931, train_acc: 64.8438\n",
            "train_loss: 0.7985, train_acc: 64.2188\n",
            "train_loss: 0.8032, train_acc: 64.2448\n",
            "train_loss: 0.8047, train_acc: 64.2857\n",
            "train_loss: 0.7974, train_acc: 64.4922\n",
            "train_loss: 0.7943, train_acc: 64.7222\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.7929, test_loss: 0.7038, train_acc: 64.8191, test_acc: 70.0568, f1_score: 0.6784\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:4\n",
            "train_loss: 0.7447, train_acc: 68.7500\n",
            "train_loss: 0.7847, train_acc: 66.3281\n",
            "train_loss: 0.7748, train_acc: 66.3021\n",
            "train_loss: 0.7558, train_acc: 67.6562\n",
            "train_loss: 0.7508, train_acc: 67.5000\n",
            "train_loss: 0.7541, train_acc: 67.1354\n",
            "train_loss: 0.7571, train_acc: 66.8750\n",
            "train_loss: 0.7523, train_acc: 67.1094\n",
            "train_loss: 0.7510, train_acc: 67.2396\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.7506, test_loss: 0.6877, train_acc: 67.2094, test_acc: 71.9034, f1_score: 0.6995\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:5\n",
            "train_loss: 0.7385, train_acc: 66.2500\n",
            "train_loss: 0.7529, train_acc: 66.3281\n",
            "train_loss: 0.7420, train_acc: 67.0833\n",
            "train_loss: 0.7244, train_acc: 68.4766\n",
            "train_loss: 0.7176, train_acc: 68.7812\n",
            "train_loss: 0.7205, train_acc: 68.8542\n",
            "train_loss: 0.7188, train_acc: 68.6830\n",
            "train_loss: 0.7136, train_acc: 68.8477\n",
            "train_loss: 0.7142, train_acc: 68.7674\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.7128, test_loss: 0.6631, train_acc: 69.0296, test_acc: 72.9545, f1_score: 0.7127\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:6\n",
            "train_loss: 0.7208, train_acc: 67.9688\n",
            "train_loss: 0.7252, train_acc: 68.0469\n",
            "train_loss: 0.7140, train_acc: 68.8021\n",
            "train_loss: 0.6885, train_acc: 70.3125\n",
            "train_loss: 0.6923, train_acc: 70.0000\n",
            "train_loss: 0.6977, train_acc: 69.9479\n",
            "train_loss: 0.7024, train_acc: 69.6875\n",
            "train_loss: 0.6971, train_acc: 69.9414\n",
            "train_loss: 0.6987, train_acc: 69.9132\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.6980, test_loss: 0.6644, train_acc: 70.0329, test_acc: 72.6136, f1_score: 0.7101\n",
            "\n",
            "epoch:7\n",
            "train_loss: 0.6764, train_acc: 68.9062\n",
            "train_loss: 0.7059, train_acc: 68.2812\n",
            "train_loss: 0.6926, train_acc: 69.0104\n",
            "train_loss: 0.6699, train_acc: 70.6641\n",
            "train_loss: 0.6674, train_acc: 70.8750\n",
            "train_loss: 0.6707, train_acc: 70.3906\n",
            "train_loss: 0.6743, train_acc: 70.1562\n",
            "train_loss: 0.6730, train_acc: 70.2539\n",
            "train_loss: 0.6691, train_acc: 70.5729\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.6650, test_loss: 0.6939, train_acc: 70.9539, test_acc: 72.5284, f1_score: 0.7059\n",
            "\n",
            "epoch:8\n",
            "train_loss: 0.6713, train_acc: 71.0938\n",
            "train_loss: 0.6793, train_acc: 72.3438\n",
            "train_loss: 0.6615, train_acc: 73.2292\n",
            "train_loss: 0.6483, train_acc: 73.7500\n",
            "train_loss: 0.6518, train_acc: 73.1875\n",
            "train_loss: 0.6541, train_acc: 72.5781\n",
            "train_loss: 0.6563, train_acc: 72.4777\n",
            "train_loss: 0.6547, train_acc: 72.5781\n",
            "train_loss: 0.6533, train_acc: 72.6042\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.6527, test_loss: 0.6771, train_acc: 72.7138, test_acc: 73.7500, f1_score: 0.7302\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:9\n",
            "train_loss: 0.6574, train_acc: 72.1875\n",
            "train_loss: 0.6610, train_acc: 71.8750\n",
            "train_loss: 0.6501, train_acc: 72.6562\n",
            "train_loss: 0.6272, train_acc: 73.7109\n",
            "train_loss: 0.6194, train_acc: 73.8438\n",
            "train_loss: 0.6276, train_acc: 73.2552\n",
            "train_loss: 0.6341, train_acc: 72.8348\n",
            "train_loss: 0.6327, train_acc: 72.9102\n",
            "train_loss: 0.6304, train_acc: 73.1944\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.6296, test_loss: 0.6642, train_acc: 73.2072, test_acc: 73.7500, f1_score: 0.7334\n",
            "\n",
            "epoch:10\n",
            "train_loss: 0.6533, train_acc: 71.8750\n",
            "train_loss: 0.6611, train_acc: 72.5000\n",
            "train_loss: 0.6351, train_acc: 73.1250\n",
            "train_loss: 0.6187, train_acc: 74.6094\n",
            "train_loss: 0.6206, train_acc: 73.9688\n",
            "train_loss: 0.6252, train_acc: 73.4115\n",
            "train_loss: 0.6263, train_acc: 73.3036\n",
            "train_loss: 0.6197, train_acc: 73.5742\n",
            "train_loss: 0.6172, train_acc: 73.5590\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.6167, test_loss: 0.6576, train_acc: 73.7993, test_acc: 73.9489, f1_score: 0.7193\n",
            "model saved to ./saved_models/best_model.pt\n",
            "new best model saved.\n",
            "\n",
            "epoch:11\n",
            "train_loss: 0.6134, train_acc: 73.9062\n",
            "train_loss: 0.6396, train_acc: 73.8281\n",
            "train_loss: 0.6145, train_acc: 74.2708\n",
            "train_loss: 0.5918, train_acc: 75.2344\n",
            "train_loss: 0.5862, train_acc: 75.0312\n",
            "train_loss: 0.5914, train_acc: 74.7396\n",
            "train_loss: 0.5979, train_acc: 74.3527\n",
            "train_loss: 0.5923, train_acc: 74.5703\n",
            "train_loss: 0.5935, train_acc: 74.5660\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.5912, test_loss: 0.6848, train_acc: 74.6217, test_acc: 73.3807, f1_score: 0.7215\n",
            "\n",
            "epoch:12\n",
            "train_loss: 0.5935, train_acc: 74.3750\n",
            "train_loss: 0.6000, train_acc: 75.0000\n",
            "train_loss: 0.5895, train_acc: 75.7292\n",
            "train_loss: 0.5682, train_acc: 76.7188\n",
            "train_loss: 0.5631, train_acc: 76.5938\n",
            "train_loss: 0.5669, train_acc: 75.8594\n",
            "train_loss: 0.5684, train_acc: 75.8482\n",
            "train_loss: 0.5675, train_acc: 76.0938\n",
            "train_loss: 0.5696, train_acc: 76.0069\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.5701, test_loss: 0.6746, train_acc: 76.0526, test_acc: 73.8068, f1_score: 0.7231\n",
            "\n",
            "epoch:13\n",
            "train_loss: 0.5637, train_acc: 77.9688\n",
            "train_loss: 0.5656, train_acc: 77.7344\n",
            "train_loss: 0.5505, train_acc: 77.3958\n",
            "train_loss: 0.5374, train_acc: 78.2031\n",
            "train_loss: 0.5411, train_acc: 77.7188\n",
            "train_loss: 0.5447, train_acc: 77.4479\n",
            "train_loss: 0.5483, train_acc: 77.2098\n",
            "train_loss: 0.5475, train_acc: 77.1680\n",
            "train_loss: 0.5454, train_acc: 77.3958\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.5420, test_loss: 0.7164, train_acc: 77.4671, test_acc: 71.0511, f1_score: 0.7037\n",
            "\n",
            "epoch:14\n",
            "train_loss: 0.5647, train_acc: 75.9375\n",
            "train_loss: 0.5645, train_acc: 76.3281\n",
            "train_loss: 0.5454, train_acc: 77.3958\n",
            "train_loss: 0.5287, train_acc: 78.0078\n",
            "train_loss: 0.5235, train_acc: 77.9062\n",
            "train_loss: 0.5256, train_acc: 77.7865\n",
            "train_loss: 0.5274, train_acc: 77.5893\n",
            "train_loss: 0.5233, train_acc: 77.5586\n",
            "train_loss: 0.5214, train_acc: 77.5174\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.5185, test_loss: 0.7162, train_acc: 77.5822, test_acc: 72.6705, f1_score: 0.7125\n",
            "\n",
            "epoch:15\n",
            "train_loss: 0.5156, train_acc: 79.2188\n",
            "train_loss: 0.5298, train_acc: 78.7500\n",
            "train_loss: 0.5219, train_acc: 78.3333\n",
            "train_loss: 0.5107, train_acc: 79.2188\n",
            "train_loss: 0.5073, train_acc: 78.8125\n",
            "train_loss: 0.5078, train_acc: 78.6458\n",
            "train_loss: 0.5099, train_acc: 78.7277\n",
            "train_loss: 0.5115, train_acc: 78.6523\n",
            "train_loss: 0.5103, train_acc: 78.7847\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.5103, test_loss: 0.7092, train_acc: 78.7500, test_acc: 71.6761, f1_score: 0.7014\n",
            "\n",
            "epoch:16\n",
            "train_loss: 0.5177, train_acc: 77.5000\n",
            "train_loss: 0.5165, train_acc: 77.6562\n",
            "train_loss: 0.5071, train_acc: 78.6458\n",
            "train_loss: 0.4910, train_acc: 79.5312\n",
            "train_loss: 0.4867, train_acc: 79.5625\n",
            "train_loss: 0.4889, train_acc: 79.7135\n",
            "train_loss: 0.4918, train_acc: 79.6652\n",
            "train_loss: 0.4890, train_acc: 79.9609\n",
            "train_loss: 0.4879, train_acc: 80.0868\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.4849, test_loss: 0.7507, train_acc: 80.2138, test_acc: 70.9659, f1_score: 0.6886\n",
            "\n",
            "epoch:17\n",
            "train_loss: 0.5043, train_acc: 78.2812\n",
            "train_loss: 0.4906, train_acc: 80.0000\n",
            "train_loss: 0.4742, train_acc: 80.9896\n",
            "train_loss: 0.4604, train_acc: 81.2500\n",
            "train_loss: 0.4550, train_acc: 81.2812\n",
            "train_loss: 0.4601, train_acc: 81.0417\n",
            "train_loss: 0.4619, train_acc: 80.9821\n",
            "train_loss: 0.4620, train_acc: 81.0938\n",
            "train_loss: 0.4675, train_acc: 80.6597\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.4666, test_loss: 0.7503, train_acc: 80.7237, test_acc: 71.1932, f1_score: 0.6997\n",
            "\n",
            "epoch:18\n",
            "train_loss: 0.4562, train_acc: 80.9375\n",
            "train_loss: 0.4602, train_acc: 81.4844\n",
            "train_loss: 0.4443, train_acc: 81.7188\n",
            "train_loss: 0.4399, train_acc: 82.1875\n",
            "train_loss: 0.4401, train_acc: 82.0000\n",
            "train_loss: 0.4397, train_acc: 81.8229\n",
            "train_loss: 0.4473, train_acc: 81.5848\n",
            "train_loss: 0.4407, train_acc: 81.9922\n",
            "train_loss: 0.4408, train_acc: 82.0660\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.4397, test_loss: 0.8042, train_acc: 82.0559, test_acc: 69.4318, f1_score: 0.6951\n",
            "\n",
            "epoch:19\n",
            "train_loss: 0.4744, train_acc: 80.0000\n",
            "train_loss: 0.4752, train_acc: 80.0781\n",
            "train_loss: 0.4644, train_acc: 81.1458\n",
            "train_loss: 0.4487, train_acc: 81.4453\n",
            "train_loss: 0.4480, train_acc: 81.3125\n",
            "train_loss: 0.4437, train_acc: 81.4062\n",
            "train_loss: 0.4459, train_acc: 81.4955\n",
            "train_loss: 0.4448, train_acc: 81.6211\n",
            "train_loss: 0.4403, train_acc: 81.9271\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.4370, test_loss: 0.9142, train_acc: 82.1053, test_acc: 71.5341, f1_score: 0.6898\n",
            "\n",
            "epoch:20\n",
            "train_loss: 0.4330, train_acc: 82.5000\n",
            "train_loss: 0.4335, train_acc: 82.1875\n",
            "train_loss: 0.4235, train_acc: 82.8646\n",
            "train_loss: 0.4071, train_acc: 82.9688\n",
            "train_loss: 0.3985, train_acc: 83.3750\n",
            "train_loss: 0.4051, train_acc: 82.9167\n",
            "train_loss: 0.3982, train_acc: 83.4598\n",
            "train_loss: 0.4021, train_acc: 83.3789\n",
            "train_loss: 0.4021, train_acc: 83.3854\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3995, test_loss: 0.9635, train_acc: 83.6020, test_acc: 69.7727, f1_score: 0.6899\n",
            "\n",
            "epoch:21\n",
            "train_loss: 0.3791, train_acc: 84.6875\n",
            "train_loss: 0.4023, train_acc: 83.9062\n",
            "train_loss: 0.4067, train_acc: 83.5417\n",
            "train_loss: 0.3939, train_acc: 84.1797\n",
            "train_loss: 0.3874, train_acc: 84.5000\n",
            "train_loss: 0.3856, train_acc: 84.4531\n",
            "train_loss: 0.3852, train_acc: 84.2411\n",
            "train_loss: 0.3798, train_acc: 84.5703\n",
            "train_loss: 0.3817, train_acc: 84.4097\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3814, test_loss: 0.8942, train_acc: 84.5559, test_acc: 68.9205, f1_score: 0.6800\n",
            "\n",
            "epoch:22\n",
            "train_loss: 0.3803, train_acc: 84.0625\n",
            "train_loss: 0.3788, train_acc: 84.3750\n",
            "train_loss: 0.3871, train_acc: 84.0104\n",
            "train_loss: 0.3662, train_acc: 85.1172\n",
            "train_loss: 0.3563, train_acc: 85.6875\n",
            "train_loss: 0.3591, train_acc: 85.6510\n",
            "train_loss: 0.3645, train_acc: 85.5804\n",
            "train_loss: 0.3671, train_acc: 85.4492\n",
            "train_loss: 0.3657, train_acc: 85.4514\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3647, test_loss: 0.9957, train_acc: 85.4770, test_acc: 69.5739, f1_score: 0.6880\n",
            "\n",
            "epoch:23\n",
            "train_loss: 0.3633, train_acc: 86.4062\n",
            "train_loss: 0.3318, train_acc: 87.8125\n",
            "train_loss: 0.3313, train_acc: 87.6042\n",
            "train_loss: 0.3275, train_acc: 87.7734\n",
            "train_loss: 0.3218, train_acc: 88.0938\n",
            "train_loss: 0.3248, train_acc: 87.7604\n",
            "train_loss: 0.3270, train_acc: 87.6562\n",
            "train_loss: 0.3313, train_acc: 87.5977\n",
            "train_loss: 0.3301, train_acc: 87.6562\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3275, test_loss: 1.0479, train_acc: 87.6809, test_acc: 69.2045, f1_score: 0.6869\n",
            "\n",
            "epoch:24\n",
            "train_loss: 0.3627, train_acc: 85.9375\n",
            "train_loss: 0.3463, train_acc: 86.4844\n",
            "train_loss: 0.3507, train_acc: 85.8854\n",
            "train_loss: 0.3437, train_acc: 86.0938\n",
            "train_loss: 0.3369, train_acc: 86.4062\n",
            "train_loss: 0.3383, train_acc: 86.3542\n",
            "train_loss: 0.3384, train_acc: 86.4062\n",
            "train_loss: 0.3348, train_acc: 86.5625\n",
            "train_loss: 0.3329, train_acc: 86.6493\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3295, test_loss: 1.0989, train_acc: 86.8586, test_acc: 69.0625, f1_score: 0.6801\n",
            "\n",
            "epoch:25\n",
            "train_loss: 0.3517, train_acc: 86.7188\n",
            "train_loss: 0.3251, train_acc: 88.2031\n",
            "train_loss: 0.3342, train_acc: 87.0833\n",
            "train_loss: 0.3248, train_acc: 87.4219\n",
            "train_loss: 0.3192, train_acc: 87.3750\n",
            "train_loss: 0.3176, train_acc: 87.5260\n",
            "train_loss: 0.3164, train_acc: 87.5223\n",
            "train_loss: 0.3159, train_acc: 87.8125\n",
            "train_loss: 0.3130, train_acc: 87.8819\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.3160, test_loss: 1.0688, train_acc: 87.6974, test_acc: 68.0682, f1_score: 0.6735\n",
            "\n",
            "epoch:26\n",
            "train_loss: 0.3108, train_acc: 87.0312\n",
            "train_loss: 0.3093, train_acc: 87.7344\n",
            "train_loss: 0.3010, train_acc: 88.1250\n",
            "train_loss: 0.2993, train_acc: 88.3594\n",
            "train_loss: 0.2993, train_acc: 88.5938\n",
            "train_loss: 0.3007, train_acc: 88.6979\n",
            "train_loss: 0.3042, train_acc: 88.5268\n",
            "train_loss: 0.3038, train_acc: 88.4961\n",
            "train_loss: 0.3040, train_acc: 88.4549\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2988, test_loss: 1.0969, train_acc: 88.6184, test_acc: 70.1989, f1_score: 0.6901\n",
            "\n",
            "epoch:27\n",
            "train_loss: 0.2706, train_acc: 89.0625\n",
            "train_loss: 0.2713, train_acc: 89.4531\n",
            "train_loss: 0.2588, train_acc: 90.0521\n",
            "train_loss: 0.2513, train_acc: 90.4688\n",
            "train_loss: 0.2681, train_acc: 89.8438\n",
            "train_loss: 0.2753, train_acc: 89.5833\n",
            "train_loss: 0.2813, train_acc: 89.2634\n",
            "train_loss: 0.2782, train_acc: 89.4141\n",
            "train_loss: 0.2787, train_acc: 89.4618\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2806, test_loss: 1.0419, train_acc: 89.3750, test_acc: 69.3466, f1_score: 0.6743\n",
            "\n",
            "epoch:28\n",
            "train_loss: 0.2796, train_acc: 90.1562\n",
            "train_loss: 0.2827, train_acc: 89.7656\n",
            "train_loss: 0.2745, train_acc: 89.6875\n",
            "train_loss: 0.2735, train_acc: 89.7266\n",
            "train_loss: 0.2697, train_acc: 89.7500\n",
            "train_loss: 0.2722, train_acc: 89.6354\n",
            "train_loss: 0.2681, train_acc: 89.8884\n",
            "train_loss: 0.2694, train_acc: 89.7266\n",
            "train_loss: 0.2695, train_acc: 89.7569\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2664, test_loss: 1.1726, train_acc: 89.9013, test_acc: 69.3466, f1_score: 0.6775\n",
            "\n",
            "epoch:29\n",
            "train_loss: 0.2327, train_acc: 90.6250\n",
            "train_loss: 0.2536, train_acc: 90.4688\n",
            "train_loss: 0.2554, train_acc: 90.3125\n",
            "train_loss: 0.2528, train_acc: 90.4297\n",
            "train_loss: 0.2584, train_acc: 90.1250\n",
            "train_loss: 0.2607, train_acc: 89.9740\n",
            "train_loss: 0.2581, train_acc: 90.1116\n",
            "train_loss: 0.2593, train_acc: 90.2148\n",
            "train_loss: 0.2665, train_acc: 90.0521\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2646, test_loss: 1.1137, train_acc: 90.1974, test_acc: 69.9148, f1_score: 0.6796\n",
            "\n",
            "epoch:30\n",
            "train_loss: 0.2722, train_acc: 89.6875\n",
            "train_loss: 0.2654, train_acc: 90.4688\n",
            "train_loss: 0.2717, train_acc: 90.3646\n",
            "train_loss: 0.2622, train_acc: 90.4297\n",
            "train_loss: 0.2586, train_acc: 90.5938\n",
            "train_loss: 0.2602, train_acc: 90.6510\n",
            "train_loss: 0.2632, train_acc: 90.5804\n",
            "train_loss: 0.2644, train_acc: 90.4688\n",
            "train_loss: 0.2620, train_acc: 90.5035\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2587, test_loss: 1.2365, train_acc: 90.4276, test_acc: 67.6420, f1_score: 0.6658\n",
            "\n",
            "epoch:31\n",
            "train_loss: 0.2528, train_acc: 90.1562\n",
            "train_loss: 0.2483, train_acc: 90.0000\n",
            "train_loss: 0.2577, train_acc: 89.6354\n",
            "train_loss: 0.2442, train_acc: 90.1562\n",
            "train_loss: 0.2468, train_acc: 90.1250\n",
            "train_loss: 0.2531, train_acc: 89.7917\n",
            "train_loss: 0.2486, train_acc: 89.9554\n",
            "train_loss: 0.2508, train_acc: 89.9023\n",
            "train_loss: 0.2465, train_acc: 90.1736\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2464, test_loss: 1.2427, train_acc: 90.2961, test_acc: 68.7784, f1_score: 0.6758\n",
            "\n",
            "epoch:32\n",
            "train_loss: 0.2491, train_acc: 90.0000\n",
            "train_loss: 0.2293, train_acc: 90.9375\n",
            "train_loss: 0.2329, train_acc: 91.0938\n",
            "train_loss: 0.2264, train_acc: 91.6016\n",
            "train_loss: 0.2262, train_acc: 91.7500\n",
            "train_loss: 0.2238, train_acc: 91.6667\n",
            "train_loss: 0.2306, train_acc: 91.4062\n",
            "train_loss: 0.2257, train_acc: 91.6602\n",
            "train_loss: 0.2254, train_acc: 91.6493\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2254, test_loss: 1.3380, train_acc: 91.6447, test_acc: 68.6364, f1_score: 0.6758\n",
            "\n",
            "epoch:33\n",
            "train_loss: 0.2176, train_acc: 90.6250\n",
            "train_loss: 0.2112, train_acc: 91.4844\n",
            "train_loss: 0.2150, train_acc: 91.7708\n",
            "train_loss: 0.2112, train_acc: 91.9922\n",
            "train_loss: 0.2123, train_acc: 92.0938\n",
            "train_loss: 0.2199, train_acc: 91.6927\n",
            "train_loss: 0.2266, train_acc: 91.3616\n",
            "train_loss: 0.2244, train_acc: 91.3672\n",
            "train_loss: 0.2239, train_acc: 91.3889\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2233, test_loss: 1.3647, train_acc: 91.3816, test_acc: 68.3523, f1_score: 0.6763\n",
            "\n",
            "epoch:34\n",
            "train_loss: 0.2143, train_acc: 92.9688\n",
            "train_loss: 0.2226, train_acc: 92.5000\n",
            "train_loss: 0.2090, train_acc: 92.8125\n",
            "train_loss: 0.2017, train_acc: 93.0859\n",
            "train_loss: 0.2050, train_acc: 92.5625\n",
            "train_loss: 0.2106, train_acc: 92.4740\n",
            "train_loss: 0.2203, train_acc: 92.0089\n",
            "train_loss: 0.2179, train_acc: 92.1875\n",
            "train_loss: 0.2153, train_acc: 92.3785\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2141, test_loss: 1.3354, train_acc: 92.3849, test_acc: 69.2614, f1_score: 0.6721\n",
            "\n",
            "epoch:35\n",
            "train_loss: 0.1981, train_acc: 92.0312\n",
            "train_loss: 0.1834, train_acc: 92.5781\n",
            "train_loss: 0.2000, train_acc: 92.1354\n",
            "train_loss: 0.1919, train_acc: 92.7344\n",
            "train_loss: 0.1972, train_acc: 92.4062\n",
            "train_loss: 0.1983, train_acc: 92.4479\n",
            "train_loss: 0.2030, train_acc: 92.1205\n",
            "train_loss: 0.2008, train_acc: 92.2852\n",
            "train_loss: 0.2038, train_acc: 92.2917\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2038, test_loss: 1.2944, train_acc: 92.2533, test_acc: 67.3580, f1_score: 0.6608\n",
            "\n",
            "epoch:36\n",
            "train_loss: 0.1882, train_acc: 93.5938\n",
            "train_loss: 0.2099, train_acc: 93.0469\n",
            "train_loss: 0.2016, train_acc: 93.0208\n",
            "train_loss: 0.2083, train_acc: 92.4609\n",
            "train_loss: 0.2005, train_acc: 92.5625\n",
            "train_loss: 0.1981, train_acc: 92.6302\n",
            "train_loss: 0.1945, train_acc: 92.8571\n",
            "train_loss: 0.2008, train_acc: 92.5586\n",
            "train_loss: 0.2022, train_acc: 92.4132\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.2036, test_loss: 1.3919, train_acc: 92.3026, test_acc: 66.0227, f1_score: 0.6437\n",
            "\n",
            "epoch:37\n",
            "train_loss: 0.1860, train_acc: 93.4375\n",
            "train_loss: 0.2096, train_acc: 92.1875\n",
            "train_loss: 0.2159, train_acc: 91.7708\n",
            "train_loss: 0.2059, train_acc: 92.1875\n",
            "train_loss: 0.1997, train_acc: 92.5938\n",
            "train_loss: 0.1998, train_acc: 92.6042\n",
            "train_loss: 0.2025, train_acc: 92.5000\n",
            "train_loss: 0.1960, train_acc: 92.8125\n",
            "train_loss: 0.1951, train_acc: 92.7431\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1945, test_loss: 1.4447, train_acc: 92.7467, test_acc: 67.5000, f1_score: 0.6633\n",
            "\n",
            "epoch:38\n",
            "train_loss: 0.1784, train_acc: 92.9688\n",
            "train_loss: 0.1726, train_acc: 93.5156\n",
            "train_loss: 0.1844, train_acc: 92.8646\n",
            "train_loss: 0.1817, train_acc: 93.2812\n",
            "train_loss: 0.1881, train_acc: 93.0938\n",
            "train_loss: 0.1860, train_acc: 93.1771\n",
            "train_loss: 0.1895, train_acc: 92.9911\n",
            "train_loss: 0.1901, train_acc: 92.9883\n",
            "train_loss: 0.1889, train_acc: 92.9514\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1879, test_loss: 1.4618, train_acc: 92.9770, test_acc: 68.2955, f1_score: 0.6775\n",
            "\n",
            "epoch:39\n",
            "train_loss: 0.1734, train_acc: 93.9062\n",
            "train_loss: 0.1712, train_acc: 93.8281\n",
            "train_loss: 0.1655, train_acc: 93.9583\n",
            "train_loss: 0.1622, train_acc: 93.9844\n",
            "train_loss: 0.1610, train_acc: 94.0312\n",
            "train_loss: 0.1676, train_acc: 93.8542\n",
            "train_loss: 0.1690, train_acc: 93.8170\n",
            "train_loss: 0.1740, train_acc: 93.6719\n",
            "train_loss: 0.1761, train_acc: 93.5764\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1761, test_loss: 1.3347, train_acc: 93.6184, test_acc: 67.5000, f1_score: 0.6652\n",
            "\n",
            "epoch:40\n",
            "train_loss: 0.1741, train_acc: 93.1250\n",
            "train_loss: 0.1705, train_acc: 93.5156\n",
            "train_loss: 0.1677, train_acc: 93.5938\n",
            "train_loss: 0.1707, train_acc: 93.2812\n",
            "train_loss: 0.1738, train_acc: 93.2500\n",
            "train_loss: 0.1729, train_acc: 93.1510\n",
            "train_loss: 0.1742, train_acc: 93.0134\n",
            "train_loss: 0.1707, train_acc: 93.2617\n",
            "train_loss: 0.1786, train_acc: 92.9861\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1766, test_loss: 1.4158, train_acc: 93.1414, test_acc: 68.2102, f1_score: 0.6752\n",
            "\n",
            "epoch:41\n",
            "train_loss: 0.1782, train_acc: 93.2812\n",
            "train_loss: 0.1879, train_acc: 93.2031\n",
            "train_loss: 0.1759, train_acc: 93.6458\n",
            "train_loss: 0.1814, train_acc: 93.7891\n",
            "train_loss: 0.1860, train_acc: 93.7812\n",
            "train_loss: 0.1871, train_acc: 93.5677\n",
            "train_loss: 0.1858, train_acc: 93.5714\n",
            "train_loss: 0.1834, train_acc: 93.7305\n",
            "train_loss: 0.1861, train_acc: 93.5590\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1863, test_loss: 1.4471, train_acc: 93.5691, test_acc: 67.1307, f1_score: 0.6552\n",
            "\n",
            "epoch:42\n",
            "train_loss: 0.2087, train_acc: 93.5938\n",
            "train_loss: 0.2056, train_acc: 93.2031\n",
            "train_loss: 0.1924, train_acc: 93.3854\n",
            "train_loss: 0.1832, train_acc: 93.5156\n",
            "train_loss: 0.1752, train_acc: 93.8750\n",
            "train_loss: 0.1735, train_acc: 94.0104\n",
            "train_loss: 0.1702, train_acc: 94.1071\n",
            "train_loss: 0.1681, train_acc: 94.1602\n",
            "train_loss: 0.1677, train_acc: 94.1667\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1664, test_loss: 1.6174, train_acc: 94.1776, test_acc: 65.0284, f1_score: 0.6469\n",
            "\n",
            "epoch:43\n",
            "train_loss: 0.1429, train_acc: 95.4688\n",
            "train_loss: 0.1767, train_acc: 94.6875\n",
            "train_loss: 0.1716, train_acc: 94.4271\n",
            "train_loss: 0.1643, train_acc: 94.6094\n",
            "train_loss: 0.1550, train_acc: 94.9062\n",
            "train_loss: 0.1609, train_acc: 94.6875\n",
            "train_loss: 0.1638, train_acc: 94.6429\n",
            "train_loss: 0.1677, train_acc: 94.4531\n",
            "train_loss: 0.1711, train_acc: 94.2188\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1714, test_loss: 1.4082, train_acc: 94.1941, test_acc: 64.8011, f1_score: 0.6381\n",
            "\n",
            "epoch:44\n",
            "train_loss: 0.1644, train_acc: 94.8438\n",
            "train_loss: 0.1710, train_acc: 94.6875\n",
            "train_loss: 0.1632, train_acc: 94.9479\n",
            "train_loss: 0.1574, train_acc: 94.8047\n",
            "train_loss: 0.1571, train_acc: 94.6562\n",
            "train_loss: 0.1606, train_acc: 94.4531\n",
            "train_loss: 0.1637, train_acc: 94.4420\n",
            "train_loss: 0.1630, train_acc: 94.4922\n",
            "train_loss: 0.1617, train_acc: 94.5139\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1612, test_loss: 1.5373, train_acc: 94.5066, test_acc: 67.5568, f1_score: 0.6608\n",
            "\n",
            "epoch:45\n",
            "train_loss: 0.1293, train_acc: 95.3125\n",
            "train_loss: 0.1276, train_acc: 95.3906\n",
            "train_loss: 0.1306, train_acc: 95.3646\n",
            "train_loss: 0.1322, train_acc: 95.5078\n",
            "train_loss: 0.1346, train_acc: 95.3125\n",
            "train_loss: 0.1411, train_acc: 95.0781\n",
            "train_loss: 0.1439, train_acc: 95.0893\n",
            "train_loss: 0.1448, train_acc: 95.0586\n",
            "train_loss: 0.1454, train_acc: 95.0174\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1460, test_loss: 1.4992, train_acc: 95.0000, test_acc: 68.6932, f1_score: 0.6680\n",
            "\n",
            "epoch:46\n",
            "train_loss: 0.1278, train_acc: 95.6250\n",
            "train_loss: 0.1101, train_acc: 95.9375\n",
            "train_loss: 0.1250, train_acc: 95.2083\n",
            "train_loss: 0.1423, train_acc: 94.5312\n",
            "train_loss: 0.1473, train_acc: 94.3750\n",
            "train_loss: 0.1519, train_acc: 94.2969\n",
            "train_loss: 0.1523, train_acc: 94.3304\n",
            "train_loss: 0.1537, train_acc: 94.3945\n",
            "train_loss: 0.1536, train_acc: 94.3576\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1532, test_loss: 1.5419, train_acc: 94.3586, test_acc: 66.5057, f1_score: 0.6567\n",
            "\n",
            "epoch:47\n",
            "train_loss: 0.1703, train_acc: 94.8438\n",
            "train_loss: 0.1635, train_acc: 94.7656\n",
            "train_loss: 0.1645, train_acc: 94.7917\n",
            "train_loss: 0.1579, train_acc: 94.8438\n",
            "train_loss: 0.1551, train_acc: 94.8125\n",
            "train_loss: 0.1505, train_acc: 94.8958\n",
            "train_loss: 0.1537, train_acc: 94.6205\n",
            "train_loss: 0.1537, train_acc: 94.6484\n",
            "train_loss: 0.1564, train_acc: 94.4097\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1552, test_loss: 1.5313, train_acc: 94.4901, test_acc: 65.5966, f1_score: 0.6564\n",
            "\n",
            "epoch:48\n",
            "train_loss: 0.1745, train_acc: 92.8125\n",
            "train_loss: 0.1649, train_acc: 93.7500\n",
            "train_loss: 0.1646, train_acc: 93.8021\n",
            "train_loss: 0.1545, train_acc: 94.4141\n",
            "train_loss: 0.1506, train_acc: 94.5000\n",
            "train_loss: 0.1491, train_acc: 94.5573\n",
            "train_loss: 0.1527, train_acc: 94.3527\n",
            "train_loss: 0.1519, train_acc: 94.3750\n",
            "train_loss: 0.1540, train_acc: 94.2535\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1513, test_loss: 1.6503, train_acc: 94.3421, test_acc: 64.9432, f1_score: 0.6398\n",
            "\n",
            "epoch:49\n",
            "train_loss: 0.1797, train_acc: 94.2188\n",
            "train_loss: 0.1663, train_acc: 93.9844\n",
            "train_loss: 0.1590, train_acc: 94.3750\n",
            "train_loss: 0.1552, train_acc: 94.4922\n",
            "train_loss: 0.1570, train_acc: 94.5000\n",
            "train_loss: 0.1544, train_acc: 94.5833\n",
            "train_loss: 0.1561, train_acc: 94.5536\n",
            "train_loss: 0.1548, train_acc: 94.6484\n",
            "train_loss: 0.1517, train_acc: 94.7222\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1499, test_loss: 1.7187, train_acc: 94.7368, test_acc: 67.6420, f1_score: 0.6690\n",
            "\n",
            "epoch:50\n",
            "train_loss: 0.1490, train_acc: 93.7500\n",
            "train_loss: 0.1414, train_acc: 94.5312\n",
            "train_loss: 0.1486, train_acc: 94.2188\n",
            "train_loss: 0.1427, train_acc: 94.6094\n",
            "train_loss: 0.1428, train_acc: 94.6250\n",
            "train_loss: 0.1494, train_acc: 94.4271\n",
            "train_loss: 0.1495, train_acc: 94.3973\n",
            "train_loss: 0.1467, train_acc: 94.4141\n",
            "train_loss: 0.1451, train_acc: 94.4965\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1427, test_loss: 1.7368, train_acc: 94.6053, test_acc: 68.4091, f1_score: 0.6710\n",
            "\n",
            "epoch:51\n",
            "train_loss: 0.1287, train_acc: 95.7812\n",
            "train_loss: 0.1403, train_acc: 95.3125\n",
            "train_loss: 0.1319, train_acc: 95.4688\n",
            "train_loss: 0.1340, train_acc: 95.3516\n",
            "train_loss: 0.1379, train_acc: 95.1875\n",
            "train_loss: 0.1356, train_acc: 95.2604\n",
            "train_loss: 0.1379, train_acc: 95.1116\n",
            "train_loss: 0.1388, train_acc: 95.0000\n",
            "train_loss: 0.1419, train_acc: 94.9132\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1415, test_loss: 1.5816, train_acc: 94.9507, test_acc: 67.9261, f1_score: 0.6757\n",
            "\n",
            "epoch:52\n",
            "train_loss: 0.1573, train_acc: 94.6875\n",
            "train_loss: 0.1327, train_acc: 95.0000\n",
            "train_loss: 0.1442, train_acc: 94.7917\n",
            "train_loss: 0.1340, train_acc: 95.0781\n",
            "train_loss: 0.1389, train_acc: 94.8438\n",
            "train_loss: 0.1415, train_acc: 94.7917\n",
            "train_loss: 0.1410, train_acc: 94.8438\n",
            "train_loss: 0.1374, train_acc: 95.0586\n",
            "train_loss: 0.1359, train_acc: 95.1910\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1352, test_loss: 1.8184, train_acc: 95.2138, test_acc: 66.1364, f1_score: 0.6485\n",
            "\n",
            "epoch:53\n",
            "train_loss: 0.1732, train_acc: 94.0625\n",
            "train_loss: 0.1513, train_acc: 94.8438\n",
            "train_loss: 0.1412, train_acc: 94.7917\n",
            "train_loss: 0.1425, train_acc: 94.9609\n",
            "train_loss: 0.1419, train_acc: 94.8438\n",
            "train_loss: 0.1402, train_acc: 94.9740\n",
            "train_loss: 0.1382, train_acc: 95.0223\n",
            "train_loss: 0.1413, train_acc: 94.9805\n",
            "train_loss: 0.1427, train_acc: 94.8090\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1423, test_loss: 1.5593, train_acc: 94.8026, test_acc: 69.1193, f1_score: 0.6767\n",
            "\n",
            "epoch:54\n",
            "train_loss: 0.1157, train_acc: 96.2500\n",
            "train_loss: 0.1191, train_acc: 95.8594\n",
            "train_loss: 0.1274, train_acc: 95.5729\n",
            "train_loss: 0.1288, train_acc: 95.5469\n",
            "train_loss: 0.1272, train_acc: 95.5312\n",
            "train_loss: 0.1307, train_acc: 95.3646\n",
            "train_loss: 0.1272, train_acc: 95.4911\n",
            "train_loss: 0.1283, train_acc: 95.4688\n",
            "train_loss: 0.1283, train_acc: 95.3646\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1269, test_loss: 1.8180, train_acc: 95.4112, test_acc: 67.0739, f1_score: 0.6604\n",
            "\n",
            "epoch:55\n",
            "train_loss: 0.1369, train_acc: 94.6875\n",
            "train_loss: 0.1426, train_acc: 94.5312\n",
            "train_loss: 0.1346, train_acc: 94.8438\n",
            "train_loss: 0.1370, train_acc: 95.0781\n",
            "train_loss: 0.1321, train_acc: 95.4062\n",
            "train_loss: 0.1339, train_acc: 95.3646\n",
            "train_loss: 0.1317, train_acc: 95.3571\n",
            "train_loss: 0.1305, train_acc: 95.2344\n",
            "train_loss: 0.1318, train_acc: 95.1910\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1307, test_loss: 1.7014, train_acc: 95.2303, test_acc: 69.6023, f1_score: 0.6726\n",
            "\n",
            "epoch:56\n",
            "train_loss: 0.1636, train_acc: 93.7500\n",
            "train_loss: 0.1541, train_acc: 94.1406\n",
            "train_loss: 0.1368, train_acc: 95.0521\n",
            "train_loss: 0.1364, train_acc: 95.3516\n",
            "train_loss: 0.1351, train_acc: 95.4062\n",
            "train_loss: 0.1356, train_acc: 95.2604\n",
            "train_loss: 0.1359, train_acc: 95.2009\n",
            "train_loss: 0.1326, train_acc: 95.3516\n",
            "train_loss: 0.1353, train_acc: 95.3472\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1345, test_loss: 1.6598, train_acc: 95.3947, test_acc: 68.4659, f1_score: 0.6516\n",
            "\n",
            "epoch:57\n",
            "train_loss: 0.1243, train_acc: 95.7812\n",
            "train_loss: 0.1388, train_acc: 94.6875\n",
            "train_loss: 0.1327, train_acc: 95.3125\n",
            "train_loss: 0.1210, train_acc: 95.5469\n",
            "train_loss: 0.1251, train_acc: 95.5000\n",
            "train_loss: 0.1267, train_acc: 95.3646\n",
            "train_loss: 0.1290, train_acc: 95.3348\n",
            "train_loss: 0.1284, train_acc: 95.4297\n",
            "train_loss: 0.1270, train_acc: 95.3472\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1246, test_loss: 1.8259, train_acc: 95.4441, test_acc: 66.9886, f1_score: 0.6507\n",
            "\n",
            "epoch:58\n",
            "train_loss: 0.1531, train_acc: 95.3125\n",
            "train_loss: 0.1260, train_acc: 96.1719\n",
            "train_loss: 0.1215, train_acc: 95.8854\n",
            "train_loss: 0.1250, train_acc: 95.8203\n",
            "train_loss: 0.1280, train_acc: 95.6875\n",
            "train_loss: 0.1246, train_acc: 95.7292\n",
            "train_loss: 0.1239, train_acc: 95.7589\n",
            "train_loss: 0.1262, train_acc: 95.6641\n",
            "train_loss: 0.1240, train_acc: 95.6771\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1221, test_loss: 1.8702, train_acc: 95.8059, test_acc: 66.0795, f1_score: 0.6507\n",
            "\n",
            "epoch:59\n",
            "train_loss: 0.1624, train_acc: 95.0000\n",
            "train_loss: 0.1313, train_acc: 95.6250\n",
            "train_loss: 0.1231, train_acc: 95.7292\n",
            "train_loss: 0.1232, train_acc: 95.8203\n",
            "train_loss: 0.1224, train_acc: 95.9375\n",
            "train_loss: 0.1283, train_acc: 95.6250\n",
            "train_loss: 0.1250, train_acc: 95.7143\n",
            "train_loss: 0.1226, train_acc: 95.7812\n",
            "train_loss: 0.1258, train_acc: 95.7986\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1248, test_loss: 1.6480, train_acc: 95.7895, test_acc: 68.3523, f1_score: 0.6738\n",
            "\n",
            "epoch:60\n",
            "train_loss: 0.1001, train_acc: 96.5625\n",
            "train_loss: 0.0858, train_acc: 97.1875\n",
            "train_loss: 0.0924, train_acc: 96.9792\n",
            "train_loss: 0.0937, train_acc: 96.7578\n",
            "train_loss: 0.1000, train_acc: 96.5625\n",
            "train_loss: 0.1022, train_acc: 96.4062\n",
            "train_loss: 0.1032, train_acc: 96.2723\n",
            "train_loss: 0.1061, train_acc: 96.1523\n",
            "train_loss: 0.1066, train_acc: 96.1806\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1088, test_loss: 1.6925, train_acc: 96.1513, test_acc: 67.5000, f1_score: 0.6642\n",
            "\n",
            "epoch:61\n",
            "train_loss: 0.0802, train_acc: 97.6562\n",
            "train_loss: 0.0978, train_acc: 97.1875\n",
            "train_loss: 0.1012, train_acc: 96.6667\n",
            "train_loss: 0.1042, train_acc: 96.3281\n",
            "train_loss: 0.1032, train_acc: 96.2188\n",
            "train_loss: 0.1058, train_acc: 96.0938\n",
            "train_loss: 0.1088, train_acc: 96.0491\n",
            "train_loss: 0.1095, train_acc: 96.0938\n",
            "train_loss: 0.1104, train_acc: 96.0590\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1111, test_loss: 1.7783, train_acc: 95.9868, test_acc: 68.3523, f1_score: 0.6745\n",
            "\n",
            "epoch:62\n",
            "train_loss: 0.1628, train_acc: 95.0000\n",
            "train_loss: 0.1444, train_acc: 95.3125\n",
            "train_loss: 0.1376, train_acc: 95.4167\n",
            "train_loss: 0.1302, train_acc: 95.7031\n",
            "train_loss: 0.1206, train_acc: 96.0312\n",
            "train_loss: 0.1244, train_acc: 95.8594\n",
            "train_loss: 0.1235, train_acc: 95.8036\n",
            "train_loss: 0.1199, train_acc: 95.9570\n",
            "train_loss: 0.1208, train_acc: 95.9375\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1189, test_loss: 1.6648, train_acc: 95.9704, test_acc: 68.7784, f1_score: 0.6750\n",
            "\n",
            "epoch:63\n",
            "train_loss: 0.1076, train_acc: 96.4062\n",
            "train_loss: 0.1218, train_acc: 95.5469\n",
            "train_loss: 0.1284, train_acc: 95.1562\n",
            "train_loss: 0.1256, train_acc: 95.3906\n",
            "train_loss: 0.1223, train_acc: 95.8438\n",
            "train_loss: 0.1230, train_acc: 95.8854\n",
            "train_loss: 0.1198, train_acc: 95.9152\n",
            "train_loss: 0.1233, train_acc: 95.8008\n",
            "train_loss: 0.1210, train_acc: 95.8507\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1174, test_loss: 1.6836, train_acc: 95.9704, test_acc: 67.8693, f1_score: 0.6757\n",
            "\n",
            "epoch:64\n",
            "train_loss: 0.1172, train_acc: 96.5625\n",
            "train_loss: 0.1164, train_acc: 96.4844\n",
            "train_loss: 0.1100, train_acc: 96.4062\n",
            "train_loss: 0.1035, train_acc: 96.6797\n",
            "train_loss: 0.1023, train_acc: 96.6250\n",
            "train_loss: 0.1015, train_acc: 96.6667\n",
            "train_loss: 0.1084, train_acc: 96.2946\n",
            "train_loss: 0.1105, train_acc: 96.1328\n",
            "train_loss: 0.1108, train_acc: 96.1111\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1102, test_loss: 1.8765, train_acc: 96.0855, test_acc: 66.5057, f1_score: 0.6563\n",
            "\n",
            "epoch:65\n",
            "train_loss: 0.1145, train_acc: 95.4688\n",
            "train_loss: 0.1131, train_acc: 95.6250\n",
            "train_loss: 0.1207, train_acc: 95.5208\n",
            "train_loss: 0.1295, train_acc: 95.1562\n",
            "train_loss: 0.1253, train_acc: 95.2500\n",
            "train_loss: 0.1217, train_acc: 95.3385\n",
            "train_loss: 0.1212, train_acc: 95.3125\n",
            "train_loss: 0.1170, train_acc: 95.5273\n",
            "train_loss: 0.1148, train_acc: 95.6944\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1132, test_loss: 1.7746, train_acc: 95.7895, test_acc: 68.5511, f1_score: 0.6702\n",
            "\n",
            "epoch:66\n",
            "train_loss: 0.1027, train_acc: 97.0312\n",
            "train_loss: 0.1026, train_acc: 96.8750\n",
            "train_loss: 0.1030, train_acc: 96.8229\n",
            "train_loss: 0.1054, train_acc: 96.6406\n",
            "train_loss: 0.1074, train_acc: 96.5312\n",
            "train_loss: 0.1090, train_acc: 96.3281\n",
            "train_loss: 0.1087, train_acc: 96.3393\n",
            "train_loss: 0.1069, train_acc: 96.3281\n",
            "train_loss: 0.1088, train_acc: 96.2847\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1071, test_loss: 1.6848, train_acc: 96.3651, test_acc: 68.1250, f1_score: 0.6608\n",
            "\n",
            "epoch:67\n",
            "train_loss: 0.1143, train_acc: 95.7812\n",
            "train_loss: 0.1128, train_acc: 96.1719\n",
            "train_loss: 0.1109, train_acc: 96.3542\n",
            "train_loss: 0.1092, train_acc: 96.4062\n",
            "train_loss: 0.1128, train_acc: 96.2500\n",
            "train_loss: 0.1133, train_acc: 96.1198\n",
            "train_loss: 0.1116, train_acc: 96.0491\n",
            "train_loss: 0.1131, train_acc: 96.0938\n",
            "train_loss: 0.1157, train_acc: 96.0069\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1140, test_loss: 1.5396, train_acc: 96.0855, test_acc: 67.7557, f1_score: 0.6566\n",
            "\n",
            "epoch:68\n",
            "train_loss: 0.1173, train_acc: 96.4062\n",
            "train_loss: 0.0981, train_acc: 96.7188\n",
            "train_loss: 0.0968, train_acc: 96.6146\n",
            "train_loss: 0.1066, train_acc: 96.4453\n",
            "train_loss: 0.1024, train_acc: 96.5625\n",
            "train_loss: 0.1051, train_acc: 96.5625\n",
            "train_loss: 0.1033, train_acc: 96.5848\n",
            "train_loss: 0.1003, train_acc: 96.6797\n",
            "train_loss: 0.1054, train_acc: 96.5451\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1048, test_loss: 1.7054, train_acc: 96.5461, test_acc: 66.9034, f1_score: 0.6520\n",
            "\n",
            "epoch:69\n",
            "train_loss: 0.1178, train_acc: 95.4688\n",
            "train_loss: 0.1340, train_acc: 94.9219\n",
            "train_loss: 0.1218, train_acc: 95.4688\n",
            "train_loss: 0.1132, train_acc: 95.9375\n",
            "train_loss: 0.1086, train_acc: 96.0312\n",
            "train_loss: 0.1125, train_acc: 95.8594\n",
            "train_loss: 0.1099, train_acc: 95.8259\n",
            "train_loss: 0.1117, train_acc: 95.8008\n",
            "train_loss: 0.1115, train_acc: 95.8507\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1105, test_loss: 1.7025, train_acc: 95.8553, test_acc: 67.5568, f1_score: 0.6552\n",
            "\n",
            "epoch:70\n",
            "train_loss: 0.0867, train_acc: 97.3438\n",
            "train_loss: 0.0874, train_acc: 97.1875\n",
            "train_loss: 0.0925, train_acc: 97.0312\n",
            "train_loss: 0.0888, train_acc: 97.1875\n",
            "train_loss: 0.0890, train_acc: 97.1875\n",
            "train_loss: 0.0923, train_acc: 96.9271\n",
            "train_loss: 0.0946, train_acc: 96.7857\n",
            "train_loss: 0.0961, train_acc: 96.8164\n",
            "train_loss: 0.0971, train_acc: 96.6840\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0970, test_loss: 1.7018, train_acc: 96.6447, test_acc: 68.2670, f1_score: 0.6604\n",
            "\n",
            "epoch:71\n",
            "train_loss: 0.0908, train_acc: 95.9375\n",
            "train_loss: 0.0949, train_acc: 96.4844\n",
            "train_loss: 0.0966, train_acc: 96.3021\n",
            "train_loss: 0.0927, train_acc: 96.5234\n",
            "train_loss: 0.0906, train_acc: 96.7188\n",
            "train_loss: 0.0911, train_acc: 96.6927\n",
            "train_loss: 0.0872, train_acc: 96.8080\n",
            "train_loss: 0.0908, train_acc: 96.7578\n",
            "train_loss: 0.0924, train_acc: 96.7361\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0952, test_loss: 1.7069, train_acc: 96.6776, test_acc: 70.1705, f1_score: 0.6773\n",
            "\n",
            "epoch:72\n",
            "train_loss: 0.0951, train_acc: 96.7188\n",
            "train_loss: 0.1025, train_acc: 96.4062\n",
            "train_loss: 0.1008, train_acc: 96.2500\n",
            "train_loss: 0.1042, train_acc: 96.2891\n",
            "train_loss: 0.1038, train_acc: 96.5000\n",
            "train_loss: 0.1022, train_acc: 96.5885\n",
            "train_loss: 0.1034, train_acc: 96.3393\n",
            "train_loss: 0.1031, train_acc: 96.3867\n",
            "train_loss: 0.1040, train_acc: 96.3194\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1033, test_loss: 1.7929, train_acc: 96.3322, test_acc: 66.5909, f1_score: 0.6625\n",
            "\n",
            "epoch:73\n",
            "train_loss: 0.0926, train_acc: 96.5625\n",
            "train_loss: 0.0926, train_acc: 96.4062\n",
            "train_loss: 0.0931, train_acc: 96.5104\n",
            "train_loss: 0.0904, train_acc: 96.4453\n",
            "train_loss: 0.0916, train_acc: 96.4062\n",
            "train_loss: 0.0971, train_acc: 96.3021\n",
            "train_loss: 0.1005, train_acc: 96.2054\n",
            "train_loss: 0.0990, train_acc: 96.3672\n",
            "train_loss: 0.0999, train_acc: 96.3194\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0996, test_loss: 1.9435, train_acc: 96.3322, test_acc: 66.3068, f1_score: 0.6638\n",
            "\n",
            "epoch:74\n",
            "train_loss: 0.0844, train_acc: 96.7188\n",
            "train_loss: 0.0829, train_acc: 97.1094\n",
            "train_loss: 0.0976, train_acc: 96.5625\n",
            "train_loss: 0.1011, train_acc: 96.2109\n",
            "train_loss: 0.1115, train_acc: 95.9688\n",
            "train_loss: 0.1071, train_acc: 96.2240\n",
            "train_loss: 0.1074, train_acc: 96.1161\n",
            "train_loss: 0.1070, train_acc: 96.1133\n",
            "train_loss: 0.1066, train_acc: 96.1979\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1047, test_loss: 1.8109, train_acc: 96.2993, test_acc: 66.5909, f1_score: 0.6611\n",
            "\n",
            "epoch:75\n",
            "train_loss: 0.0777, train_acc: 97.3438\n",
            "train_loss: 0.0886, train_acc: 96.8750\n",
            "train_loss: 0.0942, train_acc: 96.5625\n",
            "train_loss: 0.1014, train_acc: 96.3672\n",
            "train_loss: 0.1040, train_acc: 96.2500\n",
            "train_loss: 0.1021, train_acc: 96.4062\n",
            "train_loss: 0.1023, train_acc: 96.3616\n",
            "train_loss: 0.1031, train_acc: 96.3477\n",
            "train_loss: 0.1041, train_acc: 96.3715\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1018, test_loss: 1.8987, train_acc: 96.4638, test_acc: 65.7386, f1_score: 0.6522\n",
            "\n",
            "epoch:76\n",
            "train_loss: 0.0829, train_acc: 97.3438\n",
            "train_loss: 0.0823, train_acc: 97.2656\n",
            "train_loss: 0.0863, train_acc: 97.1354\n",
            "train_loss: 0.0824, train_acc: 97.2656\n",
            "train_loss: 0.0881, train_acc: 97.0625\n",
            "train_loss: 0.0939, train_acc: 96.7708\n",
            "train_loss: 0.0941, train_acc: 96.6964\n",
            "train_loss: 0.0979, train_acc: 96.5820\n",
            "train_loss: 0.0994, train_acc: 96.5278\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.1002, test_loss: 1.7975, train_acc: 96.5461, test_acc: 66.1648, f1_score: 0.6583\n",
            "\n",
            "epoch:77\n",
            "train_loss: 0.0863, train_acc: 96.8750\n",
            "train_loss: 0.0932, train_acc: 96.7969\n",
            "train_loss: 0.1059, train_acc: 96.4583\n",
            "train_loss: 0.0966, train_acc: 96.7188\n",
            "train_loss: 0.0976, train_acc: 96.7188\n",
            "train_loss: 0.0967, train_acc: 96.7188\n",
            "train_loss: 0.0936, train_acc: 96.8750\n",
            "train_loss: 0.0951, train_acc: 96.7188\n",
            "train_loss: 0.0939, train_acc: 96.7361\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0931, test_loss: 2.0324, train_acc: 96.7763, test_acc: 65.3125, f1_score: 0.6516\n",
            "\n",
            "epoch:78\n",
            "train_loss: 0.1255, train_acc: 95.6250\n",
            "train_loss: 0.1253, train_acc: 95.3125\n",
            "train_loss: 0.1182, train_acc: 95.8854\n",
            "train_loss: 0.1149, train_acc: 95.8594\n",
            "train_loss: 0.1088, train_acc: 96.0312\n",
            "train_loss: 0.1048, train_acc: 96.2500\n",
            "train_loss: 0.1001, train_acc: 96.4509\n",
            "train_loss: 0.0937, train_acc: 96.7188\n",
            "train_loss: 0.0954, train_acc: 96.6493\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0948, test_loss: 2.1705, train_acc: 96.6447, test_acc: 64.7443, f1_score: 0.6458\n",
            "\n",
            "epoch:79\n",
            "train_loss: 0.0769, train_acc: 97.1875\n",
            "train_loss: 0.0833, train_acc: 96.8750\n",
            "train_loss: 0.0871, train_acc: 96.8229\n",
            "train_loss: 0.0848, train_acc: 96.9141\n",
            "train_loss: 0.0815, train_acc: 97.0625\n",
            "train_loss: 0.0863, train_acc: 96.8490\n",
            "train_loss: 0.0920, train_acc: 96.7188\n",
            "train_loss: 0.0873, train_acc: 96.8555\n",
            "train_loss: 0.0916, train_acc: 96.7014\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0927, test_loss: 1.9752, train_acc: 96.6941, test_acc: 63.7500, f1_score: 0.6396\n",
            "\n",
            "epoch:80\n",
            "train_loss: 0.1102, train_acc: 95.7812\n",
            "train_loss: 0.0874, train_acc: 96.6406\n",
            "train_loss: 0.0937, train_acc: 96.5625\n",
            "train_loss: 0.0965, train_acc: 96.4453\n",
            "train_loss: 0.0988, train_acc: 96.4688\n",
            "train_loss: 0.0979, train_acc: 96.5104\n",
            "train_loss: 0.0989, train_acc: 96.6295\n",
            "train_loss: 0.0955, train_acc: 96.6602\n",
            "train_loss: 0.0954, train_acc: 96.6493\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0935, test_loss: 2.2103, train_acc: 96.6941, test_acc: 64.4602, f1_score: 0.6377\n",
            "\n",
            "epoch:81\n",
            "train_loss: 0.0852, train_acc: 96.4062\n",
            "train_loss: 0.1074, train_acc: 95.9375\n",
            "train_loss: 0.1013, train_acc: 96.4062\n",
            "train_loss: 0.0976, train_acc: 96.5625\n",
            "train_loss: 0.0929, train_acc: 96.6875\n",
            "train_loss: 0.0930, train_acc: 96.7188\n",
            "train_loss: 0.0907, train_acc: 96.7634\n",
            "train_loss: 0.0912, train_acc: 96.6797\n",
            "train_loss: 0.0928, train_acc: 96.6146\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0912, test_loss: 2.0188, train_acc: 96.7270, test_acc: 65.6534, f1_score: 0.6404\n",
            "\n",
            "epoch:82\n",
            "train_loss: 0.1012, train_acc: 96.5625\n",
            "train_loss: 0.0893, train_acc: 96.8750\n",
            "train_loss: 0.0859, train_acc: 97.1875\n",
            "train_loss: 0.0818, train_acc: 97.0703\n",
            "train_loss: 0.0851, train_acc: 96.9062\n",
            "train_loss: 0.0832, train_acc: 96.9531\n",
            "train_loss: 0.0831, train_acc: 96.9643\n",
            "train_loss: 0.0824, train_acc: 97.0508\n",
            "train_loss: 0.0867, train_acc: 96.9097\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0850, test_loss: 1.9819, train_acc: 97.0066, test_acc: 67.0739, f1_score: 0.6625\n",
            "\n",
            "epoch:83\n",
            "train_loss: 0.0925, train_acc: 96.4062\n",
            "train_loss: 0.0895, train_acc: 96.5625\n",
            "train_loss: 0.0860, train_acc: 96.9271\n",
            "train_loss: 0.0850, train_acc: 97.0312\n",
            "train_loss: 0.0842, train_acc: 97.0000\n",
            "train_loss: 0.0839, train_acc: 97.0833\n",
            "train_loss: 0.0835, train_acc: 97.0982\n",
            "train_loss: 0.0864, train_acc: 97.1094\n",
            "train_loss: 0.0904, train_acc: 96.9965\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0894, test_loss: 1.8372, train_acc: 97.0559, test_acc: 66.9318, f1_score: 0.6564\n",
            "\n",
            "epoch:84\n",
            "train_loss: 0.0764, train_acc: 97.1875\n",
            "train_loss: 0.0769, train_acc: 97.1094\n",
            "train_loss: 0.0924, train_acc: 96.5104\n",
            "train_loss: 0.0890, train_acc: 96.8750\n",
            "train_loss: 0.0821, train_acc: 97.1250\n",
            "train_loss: 0.0823, train_acc: 97.0052\n",
            "train_loss: 0.0831, train_acc: 96.8750\n",
            "train_loss: 0.0865, train_acc: 96.7969\n",
            "train_loss: 0.0865, train_acc: 96.8056\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0853, test_loss: 2.0080, train_acc: 96.8421, test_acc: 65.5114, f1_score: 0.6502\n",
            "\n",
            "epoch:85\n",
            "train_loss: 0.0785, train_acc: 97.3438\n",
            "train_loss: 0.0708, train_acc: 97.6562\n",
            "train_loss: 0.0759, train_acc: 97.3438\n",
            "train_loss: 0.0807, train_acc: 97.1875\n",
            "train_loss: 0.0814, train_acc: 97.1875\n",
            "train_loss: 0.0847, train_acc: 96.9792\n",
            "train_loss: 0.0839, train_acc: 97.0089\n",
            "train_loss: 0.0839, train_acc: 96.9922\n",
            "train_loss: 0.0868, train_acc: 96.9792\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0859, test_loss: 2.0209, train_acc: 97.0559, test_acc: 66.0795, f1_score: 0.6531\n",
            "\n",
            "epoch:86\n",
            "train_loss: 0.1119, train_acc: 96.8750\n",
            "train_loss: 0.1115, train_acc: 96.4062\n",
            "train_loss: 0.0926, train_acc: 97.0833\n",
            "train_loss: 0.0888, train_acc: 97.0703\n",
            "train_loss: 0.0873, train_acc: 97.1562\n",
            "train_loss: 0.0913, train_acc: 97.0312\n",
            "train_loss: 0.0931, train_acc: 96.9643\n",
            "train_loss: 0.0911, train_acc: 96.9922\n",
            "train_loss: 0.0898, train_acc: 97.0312\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0900, test_loss: 1.9670, train_acc: 97.0230, test_acc: 65.9375, f1_score: 0.6496\n",
            "\n",
            "epoch:87\n",
            "train_loss: 0.0689, train_acc: 97.6562\n",
            "train_loss: 0.0637, train_acc: 97.9688\n",
            "train_loss: 0.0620, train_acc: 97.9167\n",
            "train_loss: 0.0699, train_acc: 97.8516\n",
            "train_loss: 0.0780, train_acc: 97.2812\n",
            "train_loss: 0.0802, train_acc: 97.0833\n",
            "train_loss: 0.0801, train_acc: 97.1205\n",
            "train_loss: 0.0786, train_acc: 97.1484\n",
            "train_loss: 0.0802, train_acc: 97.1181\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0817, test_loss: 1.9882, train_acc: 97.0724, test_acc: 67.5568, f1_score: 0.6558\n",
            "\n",
            "epoch:88\n",
            "train_loss: 0.0944, train_acc: 97.5000\n",
            "train_loss: 0.0871, train_acc: 97.3438\n",
            "train_loss: 0.0856, train_acc: 97.3438\n",
            "train_loss: 0.0871, train_acc: 97.0703\n",
            "train_loss: 0.0877, train_acc: 97.1562\n",
            "train_loss: 0.0869, train_acc: 97.0573\n",
            "train_loss: 0.0867, train_acc: 97.0089\n",
            "train_loss: 0.0829, train_acc: 97.0508\n",
            "train_loss: 0.0852, train_acc: 96.9444\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0840, test_loss: 2.1033, train_acc: 97.0395, test_acc: 67.3580, f1_score: 0.6663\n",
            "\n",
            "epoch:89\n",
            "train_loss: 0.0838, train_acc: 96.4062\n",
            "train_loss: 0.0675, train_acc: 97.1094\n",
            "train_loss: 0.0795, train_acc: 96.8750\n",
            "train_loss: 0.0793, train_acc: 97.0703\n",
            "train_loss: 0.0887, train_acc: 96.8750\n",
            "train_loss: 0.0867, train_acc: 96.9531\n",
            "train_loss: 0.0875, train_acc: 97.0312\n",
            "train_loss: 0.0870, train_acc: 97.0508\n",
            "train_loss: 0.0882, train_acc: 96.9965\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0877, test_loss: 1.8741, train_acc: 97.0066, test_acc: 65.6534, f1_score: 0.6475\n",
            "\n",
            "epoch:90\n",
            "train_loss: 0.0724, train_acc: 97.5000\n",
            "train_loss: 0.0759, train_acc: 97.5781\n",
            "train_loss: 0.0848, train_acc: 97.1875\n",
            "train_loss: 0.0847, train_acc: 97.0312\n",
            "train_loss: 0.0835, train_acc: 97.1562\n",
            "train_loss: 0.0857, train_acc: 97.0573\n",
            "train_loss: 0.0883, train_acc: 96.9196\n",
            "train_loss: 0.0876, train_acc: 96.8945\n",
            "train_loss: 0.0873, train_acc: 96.7882\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0855, test_loss: 2.0163, train_acc: 96.8092, test_acc: 65.3693, f1_score: 0.6420\n",
            "\n",
            "epoch:91\n",
            "train_loss: 0.0737, train_acc: 97.8125\n",
            "train_loss: 0.0822, train_acc: 97.5000\n",
            "train_loss: 0.0754, train_acc: 97.6562\n",
            "train_loss: 0.0854, train_acc: 97.2656\n",
            "train_loss: 0.0852, train_acc: 97.3750\n",
            "train_loss: 0.0862, train_acc: 97.3177\n",
            "train_loss: 0.0876, train_acc: 97.1205\n",
            "train_loss: 0.0837, train_acc: 97.2656\n",
            "train_loss: 0.0862, train_acc: 97.1701\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0859, test_loss: 1.9446, train_acc: 97.1546, test_acc: 66.7898, f1_score: 0.6540\n",
            "\n",
            "epoch:92\n",
            "train_loss: 0.0943, train_acc: 96.7188\n",
            "train_loss: 0.0934, train_acc: 96.8750\n",
            "train_loss: 0.0935, train_acc: 96.8229\n",
            "train_loss: 0.0910, train_acc: 96.7969\n",
            "train_loss: 0.0834, train_acc: 97.0625\n",
            "train_loss: 0.0837, train_acc: 96.9531\n",
            "train_loss: 0.0828, train_acc: 97.0089\n",
            "train_loss: 0.0821, train_acc: 96.9727\n",
            "train_loss: 0.0813, train_acc: 96.9965\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0822, test_loss: 2.0064, train_acc: 96.9901, test_acc: 64.3750, f1_score: 0.6339\n",
            "\n",
            "epoch:93\n",
            "train_loss: 0.0830, train_acc: 96.4062\n",
            "train_loss: 0.0810, train_acc: 96.8750\n",
            "train_loss: 0.0783, train_acc: 96.9792\n",
            "train_loss: 0.0788, train_acc: 97.1875\n",
            "train_loss: 0.0796, train_acc: 97.1875\n",
            "train_loss: 0.0753, train_acc: 97.2917\n",
            "train_loss: 0.0794, train_acc: 97.1429\n",
            "train_loss: 0.0827, train_acc: 97.0117\n",
            "train_loss: 0.0848, train_acc: 96.9618\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0835, test_loss: 1.8940, train_acc: 97.0230, test_acc: 67.2159, f1_score: 0.6578\n",
            "\n",
            "epoch:94\n",
            "train_loss: 0.0743, train_acc: 97.3438\n",
            "train_loss: 0.0880, train_acc: 96.7969\n",
            "train_loss: 0.0824, train_acc: 96.9792\n",
            "train_loss: 0.0818, train_acc: 97.0703\n",
            "train_loss: 0.0852, train_acc: 96.9062\n",
            "train_loss: 0.0860, train_acc: 96.8490\n",
            "train_loss: 0.0858, train_acc: 96.8750\n",
            "train_loss: 0.0843, train_acc: 96.8945\n",
            "train_loss: 0.0850, train_acc: 96.8229\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0875, test_loss: 2.0018, train_acc: 96.8421, test_acc: 67.2727, f1_score: 0.6540\n",
            "\n",
            "epoch:95\n",
            "train_loss: 0.0924, train_acc: 97.0312\n",
            "train_loss: 0.0902, train_acc: 97.1094\n",
            "train_loss: 0.0905, train_acc: 97.1354\n",
            "train_loss: 0.0872, train_acc: 97.1094\n",
            "train_loss: 0.0819, train_acc: 97.2500\n",
            "train_loss: 0.0828, train_acc: 97.1354\n",
            "train_loss: 0.0856, train_acc: 96.9643\n",
            "train_loss: 0.0858, train_acc: 96.9336\n",
            "train_loss: 0.0859, train_acc: 97.0139\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0844, test_loss: 2.1195, train_acc: 97.0559, test_acc: 66.7045, f1_score: 0.6550\n",
            "\n",
            "epoch:96\n",
            "train_loss: 0.0783, train_acc: 97.3438\n",
            "train_loss: 0.0755, train_acc: 97.8125\n",
            "train_loss: 0.0792, train_acc: 97.5000\n",
            "train_loss: 0.0760, train_acc: 97.7344\n",
            "train_loss: 0.0773, train_acc: 97.5938\n",
            "train_loss: 0.0808, train_acc: 97.4219\n",
            "train_loss: 0.0792, train_acc: 97.3661\n",
            "train_loss: 0.0793, train_acc: 97.4219\n",
            "train_loss: 0.0780, train_acc: 97.5174\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0761, test_loss: 2.0534, train_acc: 97.5658, test_acc: 68.1250, f1_score: 0.6607\n",
            "\n",
            "epoch:97\n",
            "train_loss: 0.0835, train_acc: 97.1875\n",
            "train_loss: 0.0812, train_acc: 97.1094\n",
            "train_loss: 0.0856, train_acc: 97.1354\n",
            "train_loss: 0.0753, train_acc: 97.4609\n",
            "train_loss: 0.0824, train_acc: 97.2188\n",
            "train_loss: 0.0786, train_acc: 97.3958\n",
            "train_loss: 0.0751, train_acc: 97.5223\n",
            "train_loss: 0.0753, train_acc: 97.4414\n",
            "train_loss: 0.0758, train_acc: 97.4306\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0750, test_loss: 2.0590, train_acc: 97.4671, test_acc: 65.0852, f1_score: 0.6445\n",
            "\n",
            "epoch:98\n",
            "train_loss: 0.0831, train_acc: 97.0312\n",
            "train_loss: 0.0854, train_acc: 97.1875\n",
            "train_loss: 0.0873, train_acc: 97.2917\n",
            "train_loss: 0.0818, train_acc: 97.3438\n",
            "train_loss: 0.0798, train_acc: 97.4062\n",
            "train_loss: 0.0782, train_acc: 97.4219\n",
            "train_loss: 0.0792, train_acc: 97.3438\n",
            "train_loss: 0.0833, train_acc: 97.2461\n",
            "train_loss: 0.0886, train_acc: 97.0486\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0877, test_loss: 1.6585, train_acc: 97.0888, test_acc: 67.5568, f1_score: 0.6515\n",
            "\n",
            "epoch:99\n",
            "train_loss: 0.0764, train_acc: 97.1875\n",
            "train_loss: 0.0692, train_acc: 97.5000\n",
            "train_loss: 0.0726, train_acc: 97.0312\n",
            "train_loss: 0.0746, train_acc: 97.2266\n",
            "train_loss: 0.0696, train_acc: 97.4062\n",
            "train_loss: 0.0678, train_acc: 97.4479\n",
            "train_loss: 0.0695, train_acc: 97.3214\n",
            "train_loss: 0.0691, train_acc: 97.3828\n",
            "train_loss: 0.0699, train_acc: 97.4306\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0701, test_loss: 2.0236, train_acc: 97.4671, test_acc: 65.0284, f1_score: 0.6512\n",
            "\n",
            "epoch:100\n",
            "train_loss: 0.0714, train_acc: 97.6562\n",
            "train_loss: 0.0736, train_acc: 97.8125\n",
            "train_loss: 0.0836, train_acc: 97.2396\n",
            "train_loss: 0.0841, train_acc: 97.1875\n",
            "train_loss: 0.0807, train_acc: 97.3125\n",
            "train_loss: 0.0826, train_acc: 97.2135\n",
            "train_loss: 0.0792, train_acc: 97.3438\n",
            "train_loss: 0.0772, train_acc: 97.4219\n",
            "train_loss: 0.0780, train_acc: 97.3438\n",
            "Evaluating on test set...\n",
            "trian_loss: 0.0768, test_loss: 2.0783, train_acc: 97.4013, test_acc: 67.4148, f1_score: 0.6576\n",
            "Training ended with 100 epochs.\n",
            "best test_acc/f1_score: 73.94886363636364/0.719342651511285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_vocab.py --dataset \"Tweets\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXCTiP1ptcl5",
        "outputId": "e3f51e4b-1d77-4da2-ec0c-7a0ec31c3d58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading tokens...\n",
            "127741 tokens from 6051 examples loaded from ./dataset/Tweets/train.json.\n",
            "14474 tokens from 677 examples loaded from ./dataset/Tweets/test.json.\n",
            "loading glove words...\n",
            "Traceback (most recent call last):\n",
            "  File \"prepare_vocab.py\", line 131, in <module>\n",
            "    main()\n",
            "  File \"prepare_vocab.py\", line 38, in main\n",
            "    glove_vocab = load_glove_vocab(args.wv_file, args.wv_dim)\n",
            "  File \"prepare_vocab.py\", line 93, in load_glove_vocab\n",
            "    with open(filename, encoding='utf8') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'glove.840B.300d.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py --save_dir \"./saved_models/best_model.pt\" --dataset \"Tweets\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELkxSMX3ziQy",
        "outputId": "10fffacd-d4d6-4855-92b1-fb8c4bdcc4ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from Tweets with batch size 32...\n",
            "22 batches created for ./dataset/Tweets/test.json\n",
            "Loading model from ./saved_models/best_model.pt\n",
            "Namespace(batch_size=32, beta=0.0001, dataset='Tweets', decay_epoch=5, dep_dim=30, dep_vocab_size=42, direct=False, emb_dim=300, gcn_dropout=0.4, head_num=3, hidden_dim=300, input_dropout=0.7, l2reg=1e-05, log='logs.txt', log_step=20, loop=True, lower=True, lr=0.001, num_class=3, num_epoch=100, num_layers=2, optimizer='Adma', pos_dim=30, pos_vocab_size=47, post_dim=30, post_vocab_size=94, rnn_hidden=300, save_dir='./saved_models', second_layer='max', seed=241824186, theta=1.0, token_vocab_size=11322, top_k=2)\n",
            "Evaluating...\n",
            "test_loss: 19.135446548461914, test_acc: 73.94886363636364, f1_score: 0.719342651511285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHPCUn_JCPO3"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}